{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "167bb931",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c442d50",
   "metadata": {},
   "source": [
    "The aim of this project is to  build a model to classify customer reviews on product into positive and negative sentiment.\n",
    "The model may then be used on new data (reviews) to classify them into thier respective classes (negative / positive sentiment). This may help as perform further analysis on the classified reviews, eg. the frequency of positive and negative reviews, and comparison with similar data.\n",
    "\n",
    "\n",
    "## Model building process.\n",
    "\n",
    "At this stage I went through all the process involved in buiding and evaluating a supervised learning model.\n",
    "These includes:\n",
    "* data splitting\n",
    "* feature extractions\n",
    "* fitting the data with different models\n",
    "* performing model evaluations\n",
    "* comparing different models and choosing the best model.\n",
    "* tuning the best model and saving it for deployment purposes.\n",
    "\n",
    "### Findings:\n",
    "After the Exploratory Data Analysis we probabily notice what kind of data we are dealing with,is all tech gadgets possible smartphones review and other related stuffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7e0ece",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-06842cc2d8ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollocations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBigramCollocationFinder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtext_normalizer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_cloud\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/my-data-science-and-machine-learning-portfolio/sentiment-analysis/text_normalizer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0municodedata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontractions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontractions_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# NLP tools\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.collocations import FreqDist, BigramCollocationFinder\n",
    "import text_normalizer as tn\n",
    "import word_cloud as wc\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "# preprocessing tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "# algorithms\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# tuning and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b539af",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb =GaussianNB()\n",
    "lr= LogisticRegression()\n",
    "svc= SVC()\n",
    "dt= DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0ef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and perform Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bcc460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# product review\n",
    "PATH='data/sentiment labelled sentences/amazon_cells_labelled.txt',\n",
    "amazon_cells= pd.read_csv( PATH,  delimiter='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e14fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_cells.columns = ['Review', 'Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1cba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_cells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f534b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_cells.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa29de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_cells.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56491f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_cells['Sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00afffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we perform analysis on the text data\n",
    "\n",
    "reviews_list= amazon_cells['Review'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d47d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c17667b5",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Here, I performed exploratory analysis on  the data to see the kind of data I am working with.\n",
    "And also to see how often a particular word or group of words are mentioned in the reviews data.\n",
    "I also searched for **collocations** and **Named Entities**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f7151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1029d1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Search for words in capital letters\n",
    "# capatalized senetence contains mostly bad sentiment\n",
    "\n",
    "for sent in reviews_list:\n",
    "    match= re.findall(r'[A-Z]+', sent)\n",
    "    if len(match) < 4:\n",
    "        pass\n",
    "    else:\n",
    "        print(match)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcb49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list[:10]\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "token_list = []\n",
    "for s in reviews_list:\n",
    "    t = tokenizer.tokenize(s)\n",
    "    t = [w.lower() for w in t ]\n",
    "    token_list.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = [word for word in token_list if word not in stop_words]\n",
    "most_common = FreqDist(word for word in filtered_sentence)\n",
    "pd.Series(dict(most_common)).sort_values(ascending=False)[:20].\\\n",
    "                                             plot(kind='barh', figsize=(5, 7), title='Most common words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a wordcloud\n",
    "import word_cloud as wc # custom function...\n",
    "wc.show_wordcloud(filtered_sentence, max_word=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c10931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for collocation\n",
    "bgm    = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(filtered_sentence)\n",
    "scored = finder.score_ngrams( bgm.likelihood_ratio  )\n",
    "print(scored[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d351df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "collocations = pd.DataFrame(scored)\n",
    "collocations.columns = ['collocation', 'score']\n",
    "collocations.set_index('collocation', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b801fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collocations.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9978cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "collocations.head(20).plot(kind='barh', title= 'top 20 collocated words', figsize=(12, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88580c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for named entity\n",
    "\n",
    "sp = spacy.load(\"en_core_web_sm\")\n",
    "comb = ' '.join(filtered_sentence)\n",
    "comb = sp(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcda40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NE = [(word.text, word.ent_type_) for word in comb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fa938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "displacy.render(comb, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb7855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc34b83b",
   "metadata": {},
   "source": [
    "# Perform feature engineering and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing set\n",
    "\n",
    "X, y = amazon_cells['Review'], amazon_cells['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=12, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e322f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the train and test reviews\n",
    "\n",
    "X_train_norm = tn.normalize_corpus(corpus=X_train, \n",
    "                    accented_char_removal=True, \n",
    "                    html_stripping= False,\n",
    "                    contraction_expansion=False, \n",
    "                    stopword_removal=True,\n",
    "                    text_lower_case=True,\n",
    "                    remove_digits=False,\n",
    "                   )\n",
    "\n",
    "X_test_norm = tn.normalize_corpus(corpus=X_test, \n",
    "                    accented_char_removal=True, \n",
    "                    html_stripping= False,\n",
    "                    contraction_expansion=False, \n",
    "                    stopword_removal=True,\n",
    "                    text_lower_case=True,\n",
    "                    remove_digits=False,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040499c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the model using TFIDF for feature engineering..\n",
    "\n",
    "count_vect = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1, 2))\n",
    "tfidf = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5b1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train_features =count_vect.fit_transform(X_train_norm)\n",
    "cv_test_features= count_vect.transform(X_test_norm)\n",
    "\n",
    "tv_train_features=tfidf.fit_transform(X_train_norm)\n",
    "tv_test_features= tfidf.transform(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877232bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "print('train features: ', cv_train_features.shape)\n",
    "print('test features: ', cv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf \n",
    "print('train features: ', tv_train_features.shape)\n",
    "print('test features: ', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44962057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_list = [gnb, lr, svc, dt, rf]\n",
    "clf_names = ['Gaussian NB', 'Logistic Regression', 'SVC', 'Decision tree', 'Random forest']\n",
    "model_list= []\n",
    "scores_list = []\n",
    "for clf in clf_list:\n",
    "    model = clf.fit(tv_train_features.toarray(), y_train)\n",
    "    scores = clf.score(tv_test_features.toarray(), y_test) \n",
    "    model_list.append(model)\n",
    "    scores_list.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61c4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(scores_list, index=clf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a5efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review = pd.Series(['my mobile phone just got robbed, cause is so appealing to have.'])\n",
    "new_review_transformed = tfidf.transform(new_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d4f47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list[0].score(tv_test_features.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661abd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction..\n",
    "\n",
    "model_list[1].predict(new_review_transformed.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ef14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35ec7504",
   "metadata": {},
   "source": [
    "# Perform model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab53cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44698c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation scores\n",
    "k = KFold(n_splits=20)\n",
    "\n",
    "cv_scores=[]\n",
    "for model in model_list:\n",
    "    cv_ = cross_val_score(model, tv_train_features.toarray(), y_train, cv=k)\n",
    "    cv_scores.append(cv_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8f12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(cv_scores, index= clf_names).T.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3451d021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8901be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# classification reports\n",
    "predictions = []\n",
    "for name, model in zip(clf_names, model_list):\n",
    "    pred = model.predict(tv_test_features.toarray())\n",
    "    predictions.append(pred)\n",
    "    print(name+ '-classification report\\n')\n",
    "    print(classification_report(y_test, pred, target_names=['negative', 'positive']))\n",
    "    print('==========================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f81641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix \n",
    "for name, pred in zip(clf_names, predictions):\n",
    "    print(name+' confusion matrix')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, pred), \n",
    "                       index= ['positve', 'negative'], \n",
    "                       columns=['positive', 'negative']), '\\n')   \n",
    "    print('+-------------------------------------------+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc135b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bba7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curvs\n",
    "train_size, train_score, test_score = learning_curve(model_list[0], \n",
    "                             tv_train_features.toarray(),  y_train,\n",
    "                             train_sizes= np.linspace(.1, 1., 10), cv=10)\n",
    "\n",
    "train_mean =np.mean(train_score, axis=1)\n",
    "test_mean= np.mean(test_score, axis=1)\n",
    "\n",
    "train_std=np.std(train_score, axis=1)\n",
    "test_std= np.std(test_score, axis=1)\n",
    "plt.title(clf_list[0])\n",
    "plt.plot(train_size, train_mean, color='blue', label='training')\n",
    "plt.plot(train_size, test_mean, color='red', label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92deec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, train_score, test_score = learning_curve(model_list[1], \n",
    "                             tv_train_features.toarray(),  y_train,\n",
    "                             train_sizes= np.linspace(.1, 1., 10), cv=10)\n",
    "\n",
    "train_mean =np.mean(train_score, axis=1)\n",
    "test_mean= np.mean(test_score, axis=1)\n",
    "\n",
    "train_std=np.std(train_score, axis=1)\n",
    "test_std= np.std(test_score, axis=1)\n",
    "plt.title(clf_list[1])\n",
    "plt.plot(train_size, train_mean, color='blue', label='training')\n",
    "plt.plot(train_size, test_mean, color='red', label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8946429",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, train_score, test_score = learning_curve(model_list[2], \n",
    "                             tv_train_features.toarray(),  y_train,\n",
    "                             train_sizes= np.linspace(.1, 1., 10), cv=10)\n",
    "\n",
    "train_mean =np.mean(train_score, axis=1)\n",
    "test_mean= np.mean(test_score, axis=1)\n",
    "\n",
    "train_std=np.std(train_score, axis=1)\n",
    "test_std= np.std(test_score, axis=1)\n",
    "plt.title(clf_list[2])\n",
    "plt.plot(train_size, train_mean, color='blue', label='training')\n",
    "plt.plot(train_size, test_mean, color='red', label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, train_score, test_score = learning_curve(model_list[3], \n",
    "                             tv_train_features.toarray(),  y_train,\n",
    "                             train_sizes= np.linspace(.1, 1., 10), cv=10)\n",
    "\n",
    "train_mean =np.mean(train_score, axis=1)\n",
    "test_mean= np.mean(test_score, axis=1)\n",
    "\n",
    "train_std=np.std(train_score, axis=1)\n",
    "test_std= np.std(test_score, axis=1)\n",
    "plt.title(clf_list[3])\n",
    "plt.plot(train_size, train_mean, color='blue', label='training')\n",
    "plt.plot(train_size, test_mean, color='red', label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9459a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, train_score, test_score = learning_curve(model_list[4], \n",
    "                             tv_train_features.toarray(),  y_train,\n",
    "                             train_sizes= np.linspace(.1, 1., 10), cv=10)\n",
    "\n",
    "train_mean =np.mean(train_score, axis=1)\n",
    "test_mean= np.mean(test_score, axis=1)\n",
    "\n",
    "train_std=np.std(train_score, axis=1)\n",
    "test_std= np.std(test_score, axis=1)\n",
    "plt.title(clf_list[4])\n",
    "plt.plot(train_size, train_mean, color='blue', label='training')\n",
    "plt.plot(train_size, test_mean, color='red', label='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da431aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ded8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3938d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(model_list[1], 'output/model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd3853b",
   "metadata": {},
   "source": [
    "# Tuning and saving the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46729f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning the logstic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b711a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import dump\n",
    "\n",
    "pipe= Pipeline([('vectorizer', tfidf), ('clf', LogisticRegression())])\n",
    "pipe.fit(X_train_norm, y_train)\n",
    "pipe.score(X_test_norm, y_test)\n",
    "dump(pipe,'output/pipe_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.predict(['samsung is really doing bad'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad451764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "paramters = {'clf__C': [1, 10, 100, 1000, 10000],\n",
    "            'clf__tol':[0.1, 0.01, 0.001, 0.0001],\n",
    "            'clf__max_iter':[10,100, 1000, 10000],\n",
    "            'clf__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "             'clf__solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "            }\n",
    "modelGCV = GridSearchCV(pipe, paramters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e751e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGCV.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62538425",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793f4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"model performance after tuning: \",np.round(modelGCV.score(X_test_norm, y_test)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b75dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(modelGCV, 'output/model_tuned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a25359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "model_ = load('output/model_tuned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a0b3bb",
   "metadata": {},
   "source": [
    "### Evaluation report for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "pred_0 = model_.predict(X_test_norm)\n",
    "print(classification_report(y_test, pred_0, target_names= ['negative', 'positive']) ,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of the final model\n",
    "pd.DataFrame(confusion_matrix(y_test, pred_0), columns=['pos', 'neg'], index=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73061fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the outputs.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7796d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_test = np.round(model_.predict_proba(X_test_norm), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e10d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22df08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7167149b",
   "metadata": {},
   "source": [
    "At this stage, I saved the predictions made by my model into a **.csv** file plus its predict probabilities and compound (normalized score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c13be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction probabilities\n",
    "pred_prob_testdf= pd.DataFrame(pred_prob_test, columns = ['negative-score', 'positive-score'])\n",
    "pred_prob_testdf.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf54c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm_df = pd.DataFrame(X_test_norm, columns= ['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf71e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_testdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55185496",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ = pd.concat([X_test_norm_df, pred_prob_testdf], axis=1)\n",
    "scores_.to_csv('output/scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a21adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound(x, alpha=15):\n",
    "    \n",
    "    score= x/np.sqrt(x**2+alpha)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7281ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-(compound(0.565)+compound(0.435)+compound(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2781473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_testdf['compound-pos'] = compound(pred_prob_testdf['positive-score'])\n",
    "pred_prob_testdf['compound-neg'] = compound(pred_prob_testdf['negative-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f09ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the compound score we see that there is equal distribution of positive and negative \n",
    "# sentiment.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d09cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_testdf['compound-neg'].sum()/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9aa6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_testdf['compound-pos'].sum()/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the **compound** metric we see clearly that there is an equal distribution of postive and negative sentiments \n",
    "# since both compounds are around 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc247b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob_testdf.to_csv('output/scores1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5acc813",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2 = pd.concat([X_test_norm_df, pred_prob_testdf], axis=1)\n",
    "scores2.to_csv('output/scores2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048c90e",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "This ends the project on sentiment analysis using supervised machine learning approach.\n",
    "Although there are many pre-trained models such as **Vader** which performs way better than this model.\n",
    "But I only did project for learning purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
